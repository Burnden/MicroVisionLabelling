{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from pycocotools import mask\n",
    "import itertools\n",
    "import scipy.io\n",
    "import skimage.draw\n",
    "import skimage.measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_mask_area(masks):\n",
    "    return sorted(masks, reverse=True, key=mask.area)\n",
    "\n",
    "def overlapping_percentage(mask1, mask2):\n",
    "    areas = min(mask.area([mask1, mask2]))\n",
    "    if areas == 0:\n",
    "        return 0\n",
    "    percentage = mask.area(mask.merge([mask1, mask2], intersect=True))/areas\n",
    "    return percentage \n",
    "    \n",
    "# only assess the top 'process_limit' number of largest masks.\n",
    "def remove_overlapping_small_objects(masks, threshold=0.9, process_limit = 1000):\n",
    "    if len(masks) == 0:\n",
    "        return []\n",
    "    deleted_index = []\n",
    "    sorted_masks = sort_by_mask_area(masks)\n",
    "    for i, current_mask in enumerate(sorted_masks):\n",
    "        if i in deleted_index:\n",
    "            continue\n",
    "        if i > process_limit:\n",
    "            break\n",
    "        for j in range(i+1, len(sorted_masks)):\n",
    "            if j in deleted_index:\n",
    "                continue\n",
    "            test_mask = sorted_masks[j]\n",
    "            overlapping = overlapping_percentage(current_mask, test_mask)\n",
    "            if overlapping > threshold:\n",
    "                print(overlapping)\n",
    "                deleted_index.append(j)\n",
    "    return [m for i, m in enumerate(sorted_masks) if i not in deleted_index]\n",
    "\n",
    "def remove_multi_part_masks(masks, remove_all = True):\n",
    "    ret = []\n",
    "    if not len(masks):\n",
    "        return ret\n",
    "    \n",
    "    decoded_masks = mask.decode(masks)\n",
    "    for i in range(decoded_masks.shape[-1]):\n",
    "        decoded_mask = decoded_masks[:, :, i]\n",
    "        _, c, _ = cv2.findContours(decoded_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        if len(c) > 1 and remove_all:\n",
    "            continue\n",
    "        elif len(c) > 1:\n",
    "            sorted_contours = sorted(c, reverse=True, key=cv2.contourArea)\n",
    "            canvas = np.zeros(decoded_masks.shape)\n",
    "            reshaped = c[0].reshape(-1,2)\n",
    "            x = reshaped[:,0]\n",
    "            y = reshaped[:,1]\n",
    "            rr,cc = skimage.draw.polygon(y, x)\n",
    "            canvas[rr, cc] = 1\n",
    "            # print (reshaped)\n",
    "            new_mask = mask.encode(np.asfortranarray(canvas.astype(np.uint8)))[0]\n",
    "            try:\n",
    "                new_mask['is'] = masks[i]['is']\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "            ret.append(new_mask)\n",
    "        else:\n",
    "            ret.append(masks[i])\n",
    "    return ret\n",
    "def break_up_masks(masks):\n",
    "    ret = []\n",
    "    if not len(masks):\n",
    "        return ret\n",
    "    \n",
    "    decoded_masks = mask.decode(masks)\n",
    "    for i in range(decoded_masks.shape[-1]):\n",
    "        decoded_mask = decoded_masks[:, :, i]\n",
    "        _, c, _ = cv2.findContours(decoded_mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        if len(c) == 1:\n",
    "            ret.append(masks[i])\n",
    "        else:\n",
    "            for contour in c:\n",
    "                canvas = np.zeros(decoded_masks.shape)\n",
    "                reshaped = contour.reshape(-1,2)\n",
    "                x = reshaped[:,0]\n",
    "                y = reshaped[:,1]\n",
    "                rr,cc = skimage.draw.polygon(y, x)\n",
    "                canvas[rr, cc] = 1\n",
    "                new_mask = mask.encode(np.asfortranarray(canvas.astype(np.uint8)))[0]\n",
    "                try:\n",
    "                    new_mask['is'] = masks[i]['is']\n",
    "                except Exception as e:\n",
    "                    print (e)\n",
    "                ret.append(new_mask)\n",
    "    return ret\n",
    "    \n",
    "def remove_overlapping_cross_classes(multiclass_masks, threshold = 0.9, process_limit = 1000, break_parts = False, remove_multi_part = False, remove_all = True):\n",
    "    \n",
    "    #assign attribute for classification\n",
    "    for i, masks_of_one_class in enumerate(multiclass_masks):\n",
    "        for mask in masks_of_one_class:\n",
    "            mask['is'] = i\n",
    "        \n",
    "    # flatten all masks in one array\n",
    "    combined_masks = []\n",
    "    [combined_masks.extend(masks_of_one_class) for masks_of_one_class in multiclass_masks]\n",
    "    if break_parts:\n",
    "        combined_masks = break_up_masks(combined_masks)\n",
    "    processed_masks = remove_overlapping_small_objects(combined_masks, threshold, process_limit)\n",
    "    if remove_multi_part:\n",
    "        processed_masks = remove_multi_part_masks(processed_masks, remove_all)\n",
    "\n",
    "    ret =  [];\n",
    "    for i in range(len(multiclass_masks)):\n",
    "        ret.append([mask for mask in processed_masks if mask['is'] == i])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate filtered mask;\n",
    "counter = 0\n",
    "with open('infer_result' ,'rb') as input_file, open('infer_result_remove_overlapping', 'wb') as output_file:\n",
    "    try:\n",
    "        while True:\n",
    "            obj = pickle.load(input_file)\n",
    "            m = json.loads(obj['m'])\n",
    "            segms = m['cls_segms']\n",
    "            if not segms:\n",
    "                # just write it back as is\n",
    "                pickle.dump(obj, output_file)\n",
    "                continue\n",
    "            c_alpha = len(segms[1])\n",
    "            c_beta = len(segms[2])\n",
    "            m['cls_segms'] = processed = remove_overlapping_cross_classes(segms)\n",
    "            reduced_alpha = c_alpha - len(processed[1])\n",
    "            reduced_beta =  c_beta - len(processed[2])\n",
    "            if reduced_alpha or reduced_beta:\n",
    "                print(\"Alpha count reduced {}, beta count reduced {}\".format(reduced_alpha , reduced_beta))\n",
    "            \n",
    "            if counter % 100 == 0:\n",
    "                print(\"processed {} objects\".format(counter))\n",
    "            obj['m'] = json.dumps(m)\n",
    "            pickle.dump(obj, output_file)\n",
    "            counter +=1\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from pycocotools import mask\n",
    "import skimage.io as io\n",
    "import cv2\n",
    "import skimage.color as color\n",
    "import skimage.measure as measure\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "\n",
    "\n",
    "# check masks\n",
    "counter = 0\n",
    "with open('infer_result' ,'rb') as input_file:\n",
    "    [pickle.load(input_file) for _ in range(33405)]\n",
    "    try:\n",
    "        while True:\n",
    "            obj = pickle.load(input_file)\n",
    "            f = obj['f']\n",
    "            m = json.loads(obj['m'])\n",
    "            segms = m['cls_segms']\n",
    "            if not segms:\n",
    "                # just write it back as is\n",
    "                continue\n",
    "            c_alpha = len(segms[1])\n",
    "            c_beta = len(segms[2])\n",
    "            m['cls_segms'] = processed = remove_overlapping_cross_classes(segms, break_parts=True, threshold=0.2)\n",
    "            reduced_alpha = c_alpha - len(processed[1])\n",
    "            reduced_beta =  c_beta - len(processed[2])\n",
    "            if reduced_alpha or reduced_beta:\n",
    "                print(\"Alpha count reduced {}, beta count reduced {}\".format(reduced_alpha , reduced_beta))\n",
    "            \n",
    "            original_d_a = mask.decode(segms[1])\n",
    "            processed_d_a = mask.decode(processed[1])\n",
    "            original_d_b = mask.decode(segms[2])\n",
    "            processed_d_b = mask.decode(processed[2])\n",
    "            #print(len(original_d_a))\n",
    "            I = np.zeros((600,800,3)).astype(np.uint8)\n",
    "            alpha=0.5\n",
    "            \n",
    "            cur = original_d_a\n",
    "            for i in range(cur.shape[-1]):\n",
    "                colored_mask = color.grey2rgb(cur[..., i]) * [255,0,0]\n",
    "                I = cv2.addWeighted(I, 1, colored_mask.astype(np.uint8), 1-alpha, 0)\n",
    "            \n",
    "            cur = original_d_b\n",
    "            for i in range(cur.shape[-1]):\n",
    "                colored_mask = color.grey2rgb(cur[..., i]) * [0,255,0]\n",
    "                I = cv2.addWeighted(I, 1, colored_mask.astype(np.uint8), 1-alpha, 0)\n",
    "            \n",
    "            I_origin = I.copy()\n",
    "            cur = processed_d_a\n",
    "            for i in range(cur.shape[-1]):\n",
    "                #colored_mask = color.grey2rgb(cur[..., i]) * [255,255,255]\n",
    "                #I = cv2.addWeighted(I, 1, colored_mask.astype(np.uint8), 1-alpha, 0)\n",
    "                _, contours, h = cv2.findContours(cur[..., i].copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                I = cv2.drawContours(I, contours, -1, (0,0,255), 3)\n",
    "            \n",
    "            cur = processed_d_b\n",
    "            for i in range(cur.shape[-1]):\n",
    "                #colored_mask = color.grey2rgb(cur[..., i]) * [255,255,255]\n",
    "                #I = cv2.addWeighted(I, 1, colored_mask.astype(np.uint8), 1-alpha, 0)\n",
    "                _, contours, h = cv2.findContours(cur[..., i].copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                I = cv2.drawContours(I, contours, -1, (0,0,255), 3)\n",
    "                \n",
    "            \n",
    "            break\n",
    "            \n",
    "            \n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count change:`\n",
    "window_size = 2*60 # 1min\n",
    "\n",
    "alpha_count = []\n",
    "beta_count = []\n",
    "time = []\n",
    "with open('infer_result_remove_overlapping' ,'rb') as input_file:\n",
    "    try:\n",
    "        while True:\n",
    "            alpha_num = 0\n",
    "            beta_num = 0\n",
    "            time_list = []\n",
    "            for i in range(window_size):\n",
    "                obj = pickle.load(input_file)\n",
    "                try:\n",
    "                    t = int(obj['f'].split('.')[0])\n",
    "                except:\n",
    "                    continue\n",
    "                time_list.append(t)\n",
    "                m = json.loads(obj['m'])['cls_segms']\n",
    "                if not m:\n",
    "                    continue\n",
    "                m_alpha = len(m[1])\n",
    "                m_beta = len(m[2])\n",
    "                alpha_num += m_alpha\n",
    "                beta_num += m_beta\n",
    "            alpha_count.append(alpha_num)\n",
    "            beta_count.append(beta_num)\n",
    "            time.append(np.average(time_list))\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(beta_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"counts\", {\"alpha_count\": np.array(alpha_count), \"beta_count\": np.array(beta_count), \"time\": np.array(time)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate area data\n",
    "window_size = 2*60 # 1min\n",
    "\n",
    "alpha_dist = []\n",
    "beta_dist = []\n",
    "time = []\n",
    "with open('infer_result_remove_overlapping' ,'rb') as input_file:\n",
    "    try:\n",
    "        while True:\n",
    "            alpha_list = []\n",
    "            beta_list = []\n",
    "            time_list = []\n",
    "            for i in range(window_size):\n",
    "                obj = pickle.load(input_file)\n",
    "                try:\n",
    "                    t = int(obj['f'].split('.')[0])\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "                clssegms = json.loads(obj['m'])['cls_segms']\n",
    "                if clssegms:\n",
    "                    alpha_list.extend(mask.area(json.loads(obj['m'])['cls_segms'][1]).tolist())\n",
    "                    beta_list.extend(mask.area(json.loads(obj['m'])['cls_segms'][2]).tolist())\n",
    "                    time_list.append(t)\n",
    "            alpha_dist.append(alpha_list)\n",
    "            beta_dist.append(beta_list)\n",
    "            time.append(np.average(time_list))\n",
    "    except Exception as e:\n",
    "        raise (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"areas\", {\"alpha_dist\": alpha_dist, \"beta_dist\": beta_dist, \"time\": time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alpha_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ellipse data\n",
    "window_size = 2*60 # 1min\n",
    "\n",
    "alpha_ellipse = []\n",
    "beta_ellipse = []\n",
    "time = []\n",
    "with open('ellipse.p' ,'rb') as input_file:\n",
    "    try:\n",
    "        while True:\n",
    "            alpha_list = []\n",
    "            beta_list = []\n",
    "            time_list = []\n",
    "            for i in range(window_size):\n",
    "                obj = pickle.load(input_file)\n",
    "                t = obj['timestamp']\n",
    "                time_list.append(t)\n",
    "                alpha_list.extend(obj['alpha_ellipses'])\n",
    "                beta_list.extend(obj['beta_ellipses'])\n",
    "            alpha_ellipse.append(alpha_list)\n",
    "            beta_ellipse.append(beta_list)\n",
    "            time.append(np.average(time_list))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"ellipses\", {\"alpha_ellipse\": alpha_ellipse, \"beta_ellipse\": beta_ellipse, \"time\": time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.array([[[1,2]],[[3,4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.reshape(-1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
